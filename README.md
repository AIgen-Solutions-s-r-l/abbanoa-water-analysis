# Abbanoa Water Infrastructure Monitoring System

A comprehensive water infrastructure monitoring and analysis system built using Domain-Driven Design (DDD) and clean architecture principles.

## ğŸ—ï¸ Architecture Overview

This project follows Domain-Driven Design with clean architecture, organizing code into distinct layers:

```
src/
â”œâ”€â”€ domain/           # Core business logic and entities
â”œâ”€â”€ application/      # Use cases and application services
â”œâ”€â”€ infrastructure/   # External services and data persistence
â””â”€â”€ presentation/     # User interfaces (Web, CLI, API)
```

### Key Architectural Principles

- **Domain-Driven Design**: Core business logic is isolated in the domain layer
- **Clean Architecture**: Dependencies flow inward (presentation â†’ application â†’ domain)
- **Repository Pattern**: Data access is abstracted behind interfaces
- **Dependency Injection**: Loose coupling between components
- **Event-Driven**: Domain events for decoupled communication

## ğŸš€ Features

- **Real-time Monitoring**: Track water flow, pressure, and temperature across the network
- **Anomaly Detection**: Statistical analysis to identify unusual patterns
- **Consumption Analysis**: Hourly, daily, weekly, and monthly consumption patterns
- **Network Efficiency**: Calculate water loss and identify potential leakage zones
- **Multiple Interfaces**: Web dashboard, CLI tools, and REST API

## ğŸ“‹ Prerequisites

- Python 3.12+
- Poetry (for dependency management)
- Google Cloud SDK (for BigQuery integration)
- Docker (optional, for containerized deployment)

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/AIgen-Solutions-s-r-l/abbanoa-water-analysis.git
cd abbanoa-water-analysis
```

2. Install dependencies using Poetry:
```bash
poetry install
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

4. Configure BigQuery credentials:
```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/credentials.json"
```

## ğŸ¯ Quick Start

### Web Dashboard

Launch the interactive Streamlit dashboard:

```bash
poetry run streamlit run src/presentation/web/dashboard.py
```

Access the dashboard at `http://localhost:8501`

### CLI Usage

The CLI provides various commands for data management and analysis:

```bash
# Normalize sensor data
poetry run python -m src.presentation.cli.main normalize data/sensors.csv -o normalized_data

# Detect anomalies
poetry run python -m src.presentation.cli.main detect-anomalies --hours 24

# Analyze consumption patterns
poetry run python -m src.presentation.cli.main analyze-consumption --node-id NODE_ID --pattern daily

# Calculate network efficiency
poetry run python -m src.presentation.cli.main calculate-efficiency --network-id NETWORK_ID
```

### REST API

Start the FastAPI server:

```bash
poetry run uvicorn src.presentation.api.app:app --reload
```

API documentation available at `http://localhost:8000/docs`

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/               # Core business domain
â”‚   â”‚   â”œâ”€â”€ entities/         # Domain entities (SensorReading, MonitoringNode, etc.)
â”‚   â”‚   â”œâ”€â”€ value_objects/    # Value objects (Measurements, Location, etc.)
â”‚   â”‚   â”œâ”€â”€ events/           # Domain events
â”‚   â”‚   â”œâ”€â”€ exceptions/       # Domain-specific exceptions
â”‚   â”‚   â””â”€â”€ services/         # Domain services
â”‚   â”‚
â”‚   â”œâ”€â”€ application/          # Application layer
â”‚   â”‚   â”œâ”€â”€ use_cases/        # Business use cases
â”‚   â”‚   â”œâ”€â”€ interfaces/       # Repository and service interfaces
â”‚   â”‚   â””â”€â”€ dto/              # Data transfer objects
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/       # Infrastructure layer
â”‚   â”‚   â”œâ”€â”€ repositories/     # Repository implementations
â”‚   â”‚   â”œâ”€â”€ persistence/      # Database configurations
â”‚   â”‚   â”œâ”€â”€ external_services/# Third-party integrations
â”‚   â”‚   â””â”€â”€ normalization/    # Data normalization services
â”‚   â”‚
â”‚   â””â”€â”€ presentation/         # Presentation layer
â”‚       â”œâ”€â”€ web/              # Streamlit dashboard
â”‚       â”œâ”€â”€ cli/              # Command-line interface
â”‚       â””â”€â”€ api/              # REST API
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â”œâ”€â”€ integration/          # Integration tests
â”‚   â””â”€â”€ e2e/                  # End-to-end tests
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ scripts/                  # Utility scripts
â””â”€â”€ config/                   # Configuration files
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
poetry run pytest

# Run with coverage
poetry run pytest --cov=src --cov-report=html

# Run specific test categories
poetry run pytest tests/unit
poetry run pytest tests/integration
```

## ğŸ”§ Development

### Setting up pre-commit hooks:

```bash
poetry run pre-commit install
```

### Code formatting and linting:

```bash
# Format code
poetry run black src tests

# Sort imports
poetry run isort src tests

# Run linters
poetry run flake8 src tests
poetry run mypy src

# Run all checks
make quality
```

### Building documentation:

```bash
poetry run sphinx-build -b html docs docs/_build/html
```

## ğŸ“Š Data Model

### Core Entities

- **SensorReading**: Time-series measurements from sensors
- **MonitoringNode**: Physical locations with sensors
- **WaterNetwork**: Collection of interconnected nodes

### Key Measurements

- **Flow Rate** (L/s): Instantaneous water flow
- **Pressure** (bar): Water pressure in the pipes
- **Temperature** (Â°C): Water temperature
- **Volume** (mÂ³): Total water volume

## ğŸš¢ Deployment

### Docker

Build and run using Docker:

```bash
docker build -t abbanoa-water-infrastructure .
docker run -p 8501:8501 -p 8000:8000 abbanoa-water-infrastructure
```

### Google Cloud Platform

Deploy to GCP App Engine:

```bash
gcloud app deploy
```

## ğŸ“ˆ Monitoring

The system provides several monitoring capabilities:

- Real-time dashboard with key metrics
- Anomaly alerts via email/SMS
- Daily/weekly/monthly reports
- BigQuery views for custom analytics

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'feat: add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Commit Convention

We follow conventional commits:

- `feat`: New features
- `fix`: Bug fixes
- `docs`: Documentation changes
- `style`: Code style changes
- `refactor`: Code refactoring
- `test`: Test updates
- `chore`: Build/config updates

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

- **Architecture**: Domain-Driven Design implementation
- **Backend**: Python, FastAPI, BigQuery
- **Frontend**: Streamlit, Plotly
- **Infrastructure**: Google Cloud Platform

## ğŸ“ Support

For support and questions:

- Create an issue in the GitHub repository
- Contact the development team
- Check the documentation in the `docs/` directory

---

Built with â¤ï¸ by AIgen Solutions s.r.l.